{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "import cv2, numpy\n",
    "from cv2.mat_wrapper import Mat as MatLike\n",
    "\n",
    "from app.steps.enums import OnFalseEnums\n",
    "from app.adb import ADB\n",
    "\n",
    "class WorkSpaceArea():\n",
    "    def __call__(self, workspace_area):\n",
    "        if sum(workspace_area) > 0:\n",
    "            x, y, w, h = workspace_area\n",
    "            return f\"{x}x{y}+{w}+{h}\"\n",
    "        return []\n",
    "    \n",
    "\n",
    "\n",
    "class ColorTypes(Enum):\n",
    "    BGR = \"BGR\"\n",
    "    BINARY = \"BINARY\"\n",
    "    GRAYSCALE = \"GRAYSCALE\"\n",
    "    UNKNOWN = \"UNKNOWN\"\n",
    "\n",
    "\n",
    "class BitwiseScreenshotProcessor():\n",
    "    def check_image_format(self, image):\n",
    "        # if not isinstance(image, numpy.ndarray):\n",
    "        #     image = numpy.ndarray(image[0][0])\n",
    "\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            return ColorTypes.BGR\n",
    "        \n",
    "        elif len(image.shape) == 2:\n",
    "            unique_values = numpy.unique(image)\n",
    "            if set(unique_values).issubset({0, 255}):\n",
    "                return ColorTypes.BINARY\n",
    "            else:\n",
    "                return ColorTypes.GRAYSCALE\n",
    "        else:\n",
    "            return ColorTypes.UNKNOWN\n",
    "    \n",
    "    def screenshot_to_bitwise(self, screenshot_path: str | numpy.ndarray, convert_to_grayscale: bool = False, convert_to_binary: bool = False):\n",
    "        if not isinstance(screenshot_path, str):\n",
    "            return ValueError(\"Template path is not defined\")\n",
    "        bitwise_screenshot = cv2.imread(screenshot_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if convert_to_grayscale:\n",
    "            bitwise_screenshot = cv2.cvtColor(bitwise_screenshot, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if convert_to_binary:\n",
    "            _, bitwise_screenshot = cv2.threshold(bitwise_screenshot, 127, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        return bitwise_screenshot\n",
    "    \n",
    "    def bitwise_find_image_in_screen(self, screenshot: MatLike | str, template: MatLike , threshold=0.8):\n",
    "\n",
    "        if isinstance(screenshot, str):\n",
    "            template_type = self.check_image_format(template)\n",
    "\n",
    "            if template_type == ColorTypes.BGR:\n",
    "                screenshot = self.screenshot_to_bitwise(screenshot)\n",
    "            \n",
    "            if template_type == ColorTypes.BINARY:\n",
    "                screenshot = self.screenshot_to_bitwise(screenshot, convert_to_binary=True, convert_to_grayscale=True)\n",
    "\n",
    "            if template_type == ColorTypes.GRAYSCALE:\n",
    "                screenshot = self.screenshot_to_bitwise(screenshot, convert_to_grayscale=True)\n",
    "            \n",
    "\n",
    "        result = cv2.matchTemplate(screenshot, template, cv2.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        location = numpy.where(result >= threshold)\n",
    "\n",
    "        matched_coordinates = []\n",
    "        for pt in zip(*location[::-1]):\n",
    "            matched_coordinates.append((pt[0], pt[1]))\n",
    "\n",
    "        if matched_coordinates:\n",
    "            return True \n",
    "        return False\n",
    "    \n",
    "    def bitwise_crop(self, screenshot: MatLike, coordinates: list[int]):\n",
    "        x, y, w, h = coordinates\n",
    "        return screenshot[y:y + h, x:x + w]\n",
    "    \n",
    "    \n",
    "\n",
    "class ScreenshotProcessor(BitwiseScreenshotProcessor):\n",
    "    def crop(self, screenshot_path: str, coordinates: list[int], output_path: str):\n",
    "        # Read the image from the specified path\n",
    "        screenshot = cv2.imread(screenshot_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # Check if the image was loaded successfully\n",
    "        if screenshot is None:\n",
    "            raise FileNotFoundError(f\"Could not load image at path: {screenshot_path}\")\n",
    "\n",
    "        # Ensure the coordinates are valid\n",
    "        if len(coordinates) != 4:\n",
    "            raise ValueError(\"Coordinates should be a list of four integers: [x, y, width, height].\")\n",
    "        \n",
    "        x, y, w, h = coordinates\n",
    "        height, width = screenshot.shape[:2]\n",
    "        print(height, width)\n",
    "        print(coordinates)\n",
    "        # Check if the coordinates are within the bounds of the image\n",
    "        if x < 0 or y < 0 or x + w > screenshot.shape[1] or y + h > screenshot.shape[0]:\n",
    "            raise ValueError(\"Crop coordinates are out of bounds.\")\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = screenshot[y:y + h, x:x + w]\n",
    "\n",
    "        # Save the cropped image to the specified output path\n",
    "        success = cv2.imwrite(output_path, cropped_image)\n",
    "\n",
    "        if not success:\n",
    "            raise IOError(f\"Failed to write image to path: {output_path}\")\n",
    "\n",
    "        return success  # Return whether the writing was successful\n",
    "    \n",
    "    def find_image_in_screenshot(screenshot_path: str, template_path: str, threshold=0.8):\n",
    "        # Load the screenshot and the template imageÑ‘\n",
    "        screenshot = cv2.imread(screenshot_path)  \n",
    "        template = cv2.imread(template_path)\n",
    "\n",
    "        # Convert both images to grayscale\n",
    "        # screenshot_gray = cv2.cvtColor(screenshot, cv2.COLOR_BGR2GRAY)\n",
    "        # template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Match the template using cv2.matchTemplate\n",
    "        result = cv2.matchTemplate(screenshot, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "        # Find the locations where the match exceeds the threshold\n",
    "        loc = numpy.where(result >= threshold)\n",
    "\n",
    "        # Collecting the coordinates of matched areas\n",
    "        matched_coordinates = []\n",
    "        for pt in zip(*loc[::-1]):  # Switch columns and rows\n",
    "            matched_coordinates.append((pt[0], pt[1]))  # Append (x, y) coordinates\n",
    "\n",
    "        if matched_coordinates:\n",
    "            return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.adb import ADB\n",
    "\n",
    "adb = ADB(\"emulator-5554\")\n",
    "adb.ScreenCapture(path=\"./screenshots/\", name=\"screenshot\")\n",
    "\n",
    "bit_proc = BitwiseScreenshotProcessor()\n",
    "template = bit_proc.screenshot_to_bitwise(\"./screenshots/youtube_toolbar.png\", convert_to_binary=True)\n",
    "# template = \"./screenshots/template.png\"\n",
    "screenshot = bit_proc.screenshot_to_bitwise(\"./screenshots/screenshot.png\", convert_to_binary=True)\n",
    "bit_proc.bitwise_crop(screenshot, [2, 1208, 715, 66])\n",
    "\n",
    "bit_proc.bitwise_find_image_in_screen(screenshot, template, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import time\n",
    "\n",
    "from app.adb import ADB\n",
    "from app.adb import LDConnector\n",
    "from app.steps.enums import OnFalseEnums, StepTypesEnums\n",
    "from app.steps import ClickStep, ValidatorStep, InputStep, ScreenGetterStep, Step, BitwiseScreenshotProcessor, ScreenshotProcessor\n",
    "from config import load_config\n",
    "\n",
    "@dataclass(init=False)\n",
    "class StepData:\n",
    "    step_name: str\n",
    "    screenshot_name: str\n",
    "    type: str\n",
    "    extra_args: list = field(default_factory=list)\n",
    "    extra_kwargs: dict = field(default_factory=dict)\n",
    "\n",
    "    def __init__(self, step_name: str, screenshot_name: str, type: str, *args, **kwargs):\n",
    "        self.step_name = step_name\n",
    "        self.screenshot_name = screenshot_name\n",
    "        self.type = type\n",
    "        self.extra_args = args\n",
    "        self.extra_kwargs = kwargs\n",
    "        \n",
    "class StepManager():\n",
    "    def __init__(self, config: str):\n",
    "        self.adb = ADB(emulator_name=\"emulator-5554\")\n",
    "        self.ldplayer = LDConnector()\n",
    "        self.emulator_name = \"emulator-5554\"\n",
    "        self.steps = []\n",
    "        self.config = load_config(config)\n",
    "        self.screenshots_path = self.config.get(\"screenshots_path\")\n",
    "        self.work_dir = self.config.get(\"work_dir\")\n",
    "        self.screen_processor = ScreenshotProcessor()\n",
    "        self.bitwise_screen_processor = BitwiseScreenshotProcessor()\n",
    "\n",
    "        for step in self.config.get(\"steps\"):\n",
    "            data = StepData(**step)\n",
    "\n",
    "            if data.type == StepTypesEnums.button.value:\n",
    "                self.steps.append(ClickStep(**step))\n",
    "\n",
    "            if data.type == StepTypesEnums.input_filed.value:\n",
    "                self.steps.append(InputStep(**step))\n",
    "\n",
    "            if data.type == StepTypesEnums.validator.value:\n",
    "                self.steps.append(ValidatorStep(**step))\n",
    "\n",
    "    def initialize_steps_binary(self, screenshots_work_dir):\n",
    "        for step in self.steps:\n",
    "            try:\n",
    "                step.bitwise_screenshot_with_workspace_area(screenshots_work_dir)\n",
    "            except:\n",
    "                ValueError(f\"Step {step.step_name} not initialized\")\n",
    "\n",
    "    def validate_screenshot(self, step: Step, attemp_delay = 0.25):\n",
    "        attemps = 1\n",
    "        print(f\"Validating {step.step_name}\")\n",
    "        print(step.on_false)\n",
    "\n",
    "        while attemps <= step.retries_limit:\n",
    "            self.adb.ScreenCapture(self.work_dir, self.emulator_name)\n",
    "\n",
    "            if hasattr(step, \"bitwise_screenshot\"):\n",
    "                screenshot = self.bitwise_screen_processor.screenshot_to_bitwise(f\"{self.screenshots_path}{step.screenshot_name}\")\n",
    "                result = self.bitwise_screen_processor.bitwise_find_image_in_screen(\n",
    "                    step.bitwise_screenshot, \n",
    "                    f\"{self.work_dir}{self.emulator_name}.png\", \n",
    "                    step.threshold)\n",
    "            else:\n",
    "                print(f\"screenshot: {self.screenshots_path}{step.screenshot_name}\")\n",
    "                print(f\"{self.work_dir}{self.emulator_name}.png\")\n",
    "\n",
    "                result = self.screen_processor.find_image_in_screenshot(f\"{self.screenshots_path}{step.screenshot_name}\", f\"{self.work_dir}{self.emulator_name}.png\", step.threshold)\n",
    "\n",
    "            if not result and step.on_false == OnFalseEnums.skip:\n",
    "                logging.debug(f\"Skipping {step.step_name}\")\n",
    "                return OnFalseEnums.skip\n",
    "\n",
    "            if not result:\n",
    "                logging.debug(f\"State of {step.step_name} screenshot not valid, trying again. Retries {attemps}\")\n",
    "                attemps += 1\n",
    "                logging.debug(attemp_delay)\n",
    "                continue\n",
    "\n",
    "            if result:\n",
    "                logging.debug(f\"Valide state of {step.step_name} after {attemps} retries\")\n",
    "                return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.steps import ScreenGetterStep\n",
    "\n",
    "first = ScreenGetterStep(\n",
    "    step_name = \"toolbar\",\n",
    "    screenshot_name=\"youtube_toolbar.png\",\n",
    "    type = \"screen_getter\",\n",
    "    required_screen_check=True,\n",
    "    workspace_area=[2, 1208, 715, 66]\n",
    ")\n",
    "\n",
    "first.init_bitwise(work_dir = \"./screenshots\")\n",
    "\n",
    "# manager = StepManager(\"racer-pointx.yml\")\n",
    "\n",
    "# manager.validate_screenshot(first)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
